{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Funzione per calcolare la distanza euclidea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclideanDistance(ex, query):\n",
    "    distance = np.linalg.norm(ex - query)\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visto che peseremo i risultati in base alla distanza serve una funzione per definire il peso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightByDistance(distance):\n",
    "    weight = 1/distance\n",
    "    return weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K-NN pesato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''def kNN_weighted(examples, query, k):\n",
    "    class_distance = []\n",
    "    for i in range(examples.shape[0]):\n",
    "        classe = examples.at[i, 'hazardous']\n",
    "        single_example = examples.loc[i].drop('hazardous').values\n",
    "        distance = euclideanDistance(single_example, query.values)\n",
    "        if distance == 0:\n",
    "            return classe\n",
    "        class_distance.append((distance, classe))\n",
    "\n",
    "    class_distance = sorted(class_distance)[:k]\n",
    "    freq_hazardous = 0\n",
    "    freq_not_hazardous = 0\n",
    "\n",
    "    for example in class_distance:\n",
    "        if example[1] == 'True':\n",
    "            freq_hazardous = freq_hazardous + weightByDistance(example[0])\n",
    "        else:\n",
    "            freq_not_hazardous = freq_not_hazardous + weightByDistance(example[0])\n",
    "\n",
    "    if freq_hazardous  > freq_not_hazardous :\n",
    "        return 'True'\n",
    "    else:\n",
    "        return 'False'\n",
    "'''\n",
    "\n",
    "def kNN_weighted(examples, query, k):\n",
    "    class_distance = []\n",
    "    query_values = query.values\n",
    "    query_weight = weightByDistance(np.linalg.norm(examples.drop('hazardous', axis=1) - query_values, axis=1))\n",
    "    class_distance = list(zip(query_weight, examples['hazardous']))\n",
    "\n",
    "    class_distance.sort(reverse=True)  # Ordinamento basato sui pesi\n",
    "\n",
    "    freq_hazardous = sum(w for w, c in class_distance[:k] if c == True)\n",
    "    freq_not_hazardous = sum(w for w, c in class_distance[:k] if c == False)\n",
    "\n",
    "    if freq_hazardous > freq_not_hazardous:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matrice di confusione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusionMatrix(classi):\n",
    "    # True hazardous\n",
    "    TH = classi.loc[(classi['hazardous'] == True) & (classi['hazardous_predicted'] == True)].reset_index(drop=True).shape[0] \n",
    "    # False hazardous\n",
    "    FH = classi.loc[(classi['hazardous'] == False) & (classi['hazardous_predicted'] == True)].reset_index(drop=True).shape[0]\n",
    "    # False not hazardous\n",
    "    FNH = classi.loc[(classi['hazardous'] == True) & (classi['hazardous_predicted'] == False)].reset_index(drop=True).shape[0]\n",
    "    # True not hazardous\n",
    "    TNH = classi.loc[(classi['hazardous'] == False) & (classi['hazardous_predicted'] == False)].reset_index(drop=True).shape[0]\n",
    "\n",
    "    conf_matrix = pd.DataFrame({\"True\": [TH, FH], \"False\": [FNH, TNH]}, index = [\"True\", \"False\"])\n",
    "    \n",
    "    return(conf_matrix, TH, FH, FNH, TNH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(TH, FH, FNH, TNH):\n",
    "    m = TH + FH + FNH + TNH\n",
    "\n",
    "    # classificazioni corrette\n",
    "    correct_classifications = TH + TNH\n",
    "    accuracy = correct_classifications / m\n",
    "    accuracy_percentage = accuracy * 100\n",
    "    print(\"Accuratezza del modello (istanze classificate correttamente) => \" + str(round(accuracy_percentage, 5)) + \"\\nN째 classificazioni corrette =>\" + str(correct_classifications))\n",
    "\n",
    "    #classificazioni errate\n",
    "    incorrect_classifications = FH + FNH\n",
    "    inaccuracy = incorrect_classifications / m\n",
    "    inaccuracy_percentage = inaccuracy * 100\n",
    "    print(\"Imprecisione del modello (istanze classificate incorrettamente) => \" + str(round(inaccuracy_percentage, 5)) + \"\\nN째 classificazioni sbagliate =>\" + str(incorrect_classifications))\n",
    "\n",
    "    #coeff Kappa\n",
    "    p_hazardous = ((TH + FNH)/m) * ((TH + FH)/m)\n",
    "    p_not_hazardous = ((TNH + FH)/m) * ((TNH + FNH)/m)\n",
    "    p_e = p_hazardous + p_not_hazardous\n",
    "    k_coeff = (accuracy - p_e) / (1 - p_e)\n",
    "    print(\"Kappa coefficient => \" + str(round(k_coeff, 5)))\n",
    "\n",
    "    print(\"\\n######## STATISTICHE DELLE DUE CLASSI ########\")\n",
    "    print(\"\\n++++++++ HAZARDOUS ++++++++\")\n",
    "    precision = TH / (TH + FH)\n",
    "    print(\"Precisione = \" + str(round(precision, 5)))\n",
    "    recall = TH / (TH + FNH)\n",
    "    print(\"Recall = \" + str(round(recall, 5)))\n",
    "    F1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "    print(\"F1 score = \" + str(round(F1_score, 5)))\n",
    "\n",
    "    print(\"\\n-------- NOT HAZARDOUS -------\")\n",
    "    precision = TNH / (TNH + FNH)\n",
    "    print(\"Precisione = \" + str(round(precision, 5)))\n",
    "    recall = TNH / (TNH + FH)\n",
    "    print(\"Recall = \" + str(round(recall, 5)))\n",
    "    F1_score = 2 * ((precision * recall) / (precision + recall))\n",
    "    print(\"F1 score = \" + str(round(F1_score, 5)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "caricamento del dataset e definizione del numero di vicini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('neo_v2_edited.csv')\n",
    "\n",
    "dataset = dataset.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "k=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\n******* TEST MODE: SPLIT 70% TRAIN, REMAINDER TEST *******')\n",
    "\n",
    "# Splitting training/test set (70% training set e 30% test set)\n",
    "training_set = dataset.head(round(len(dataset)*(70/100))) # arrotondo per eccesso\n",
    "test_set = dataset.tail(len(dataset) - len(training_set)).reset_index(drop=True)\n",
    "test_set['hazardous_predicted'] = np.zeros(test_set.shape[0])    # viene inserita la classe predetta\n",
    "\n",
    "for i in range(test_set.shape[0]):\n",
    "    if i%100 == 0:\n",
    "        print('Predico query numero ' + str(i))\n",
    "    query = test_set[i:(i+1)].drop('hazardous', axis = 1).drop('hazardous_predicted', axis = 1).reset_index(drop=True)\n",
    "    test_set.at[i,'hazardous_predicted'] = kNN_weighted(training_set, query, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Valutazione"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------- MATRICE DI CONFUSIONE -------\n",
      "       True  False\n",
      "True    142    561\n",
      "False    53   7471\n",
      "Accuratezza del modello (istanze classificate correttamente) => 92.53677\n",
      "N째 classificazioni corrette =>7613\n",
      "Imprecisione del modello (istanze classificate incorrettamente) => 7.46323\n",
      "N째 classificazioni sbagliate =>614\n",
      "Kappa coefficient => 0.28991\n",
      "\n",
      "######## STATISTICHE DELLE DUE CLASSI ########\n",
      "\n",
      "++++++++ HAZARDOUS ++++++++\n",
      "Precisione = 0.72821\n",
      "Recall = 0.20199\n",
      "F1 score = 0.31626\n",
      "\n",
      "-------- NOT HAZARDOUS -------\n",
      "Precisione = 0.93015\n",
      "Recall = 0.99296\n",
      "F1 score = 0.96053\n"
     ]
    }
   ],
   "source": [
    "print('\\n------- MATRICE DI CONFUSIONE -------')\n",
    "classi = test_set[['hazardous','hazardous_predicted']]\n",
    "(confusione, TH, FH, FNH, TNH) = confusionMatrix(classi)\n",
    "print(confusione)\n",
    "\n",
    "evaluation(TH, FH, FNH, TNH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
